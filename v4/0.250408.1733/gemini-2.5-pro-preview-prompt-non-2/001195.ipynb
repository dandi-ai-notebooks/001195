{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21a55e3",
   "metadata": {},
   "source": [
    "# Exploring Dandiset 001195: Separable Dorsal Raphe Dopamine Projections Mediate the Facets of Loneliness-like State\n",
    "\n",
    "**Dandiset Version:** 0.250408.1733\n",
    "\n",
    "**Note:** This notebook was AI-generated and has not been fully verified. Please be cautious when interpreting the code or results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfbc9b0",
   "metadata": {},
   "source": [
    "## Overview of the Dandiset\n",
    "\n",
    "This Dandiset, titled \"Separable Dorsal Raphe Dopamine Projections Mediate the Facets of Loneliness-like State,\" contains supporting data for the publication by Lee, Matthews, et al. (2025). The research investigates how different dopamine projections from the dorsal raphe nucleus (DRN) influence aspects of loneliness-like states in mice.\n",
    "\n",
    "The dataset includes:\n",
    "- In vivo calcium imaging data\n",
    "- Supporting behavioral videos\n",
    "- Ex vivo patch-clamp electrophysiology recordings\n",
    "\n",
    "**Key areas of study:** Dorsal Raphe Nucleus (DRN), Central Amygdala (CeA), Bed Nucleus of the Stria Terminalis (BNST), Posterior Basolateral Amygdala (BLP).\n",
    "\n",
    "**Experimental manipulations/observations:** Optogenetics, social isolation, social motivation.\n",
    "\n",
    "**Link to the Dandiset:** [https://dandiarchive.org/dandiset/001195/0.250408.1733](https://dandiarchive.org/dandiset/001195/0.250408.1733)\n",
    "\n",
    "## What this notebook covers\n",
    "\n",
    "This notebook will guide you through:\n",
    "1. Loading the Dandiset information using the DANDI API.\n",
    "2. Listing some of the assets (files) within the Dandiset.\n",
    "3. Selecting an NWB (Neurodata Without Borders) file from the Dandiset.\n",
    "4. Loading and inspecting metadata from the selected NWB file.\n",
    "5. Loading and visualizing some electrophysiology data (current clamp series) from the NWB file.\n",
    "\n",
    "## Required Packages\n",
    "\n",
    "To run this notebook, you will need the following Python packages. It is assumed they are already installed:\n",
    "- `dandi` (for interacting with the DANDI Archive)\n",
    "- `pynwb` (for working with NWB files)\n",
    "- `h5py` (for HDF5 file support, used by PyNWB)\n",
    "- `remfile` (for accessing remote files)\n",
    "- `numpy` (for numerical operations)\n",
    "- `matplotlib` (for plotting)\n",
    "- `seaborn` (for enhanced visualizations)\n",
    "\n",
    "No `pip install` commands are included in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81c28e",
   "metadata": {},
   "source": [
    "## 1. Load Dandiset Information with DANDI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c353f433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:58:28.371623Z",
     "iopub.status.busy": "2025-05-09T15:58:28.371369Z",
     "iopub.status.idle": "2025-05-09T15:58:28.797384Z",
     "shell.execute_reply": "2025-05-09T15:58:28.796625Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '환경'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m islice\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdandi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdandiapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DandiAPIClient\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m환경\u001b[39;00m \u001b[38;5;66;03m# This is a placeholder, will be replaced by actual environment variables or configuration\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '환경'"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "import 환경 # This is a placeholder, will be replaced by actual environment variables or configuration\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pynwb\n",
    "import h5py\n",
    "import remfile\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seaborn theme for plotting\n",
    "sns.set_theme()\n",
    "\n",
    "# Connect to DANDI archive\n",
    "client = DandiAPIClient()\n",
    "dandiset_id = \"001195\"\n",
    "dandiset_version = \"0.250408.1733\" # Latest version as of notebook creation\n",
    "dandiset = client.get_dandiset(dandiset_id, dandiset_version)\n",
    "\n",
    "# Print basic information about the Dandiset\n",
    "metadata = dandiset.get_raw_metadata()\n",
    "print(f\"Dandiset name: {metadata['name']}\")\n",
    "print(f\"Dandiset URL: {dandiset.get_metadata().url}\") # Using .get_metadata().url for the correct URL\n",
    "print(f\"Dandiset description: {metadata.get('description', 'No description available.')}\")\n",
    "\n",
    "# List some assets in the Dandiset\n",
    "assets = dandiset.get_assets()\n",
    "print(\"\\nFirst 5 assets:\")\n",
    "for asset in islice(assets, 5):\n",
    "    print(f\"- {asset.path} (ID: {asset.identifier})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf3d17",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect an NWB File\n",
    "\n",
    "We will now select one of the NWB files from the Dandiset to explore its contents.\n",
    "\n",
    "We will use the following file:\n",
    "**Path:** `sub-23/sub-23_ses-20150324T134114_slice-slice-1_cell-C1_icephys.nwb`\n",
    "**Asset ID:** `a243dde4-c270-42a9-8550-025f5ffcd5a7`\n",
    "\n",
    "The direct download URL for this asset is:\n",
    "`https://api.dandiarchive.org/api/assets/a243dde4-c270-42a9-8550-025f5ffcd5a7/download/`\n",
    "\n",
    "We will use `remfile` and `pynwb` to load this NWB file directly from its URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af0bddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:58:28.798989Z",
     "iopub.status.busy": "2025-05-09T15:58:28.798815Z",
     "iopub.status.idle": "2025-05-09T15:58:28.810587Z",
     "shell.execute_reply": "2025-05-09T15:58:28.810124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NWB file from: https://api.dandiarchive.org/api/assets/a243dde4-c270-42a9-8550-025f5ffcd5a7/download/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'remfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading NWB file from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnwb_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the NWB file\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# The following lines are based on the output from `tools_cli.py nwb-file-info`\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m remote_file \u001b[38;5;241m=\u001b[39m \u001b[43mremfile\u001b[49m\u001b[38;5;241m.\u001b[39mFile(nwb_url)\n\u001b[1;32m      9\u001b[0m h5_file \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(remote_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Ensure read-only mode\u001b[39;00m\n\u001b[1;32m     10\u001b[0m io \u001b[38;5;241m=\u001b[39m pynwb\u001b[38;5;241m.\u001b[39mNWBHDF5IO(file\u001b[38;5;241m=\u001b[39mh5_file, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Ensure read-only mode\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remfile' is not defined"
     ]
    }
   ],
   "source": [
    "# URL of the selected NWB file\n",
    "nwb_asset_id = \"a243dde4-c270-42a9-8550-025f5ffcd5a7\"\n",
    "nwb_url = f\"https://api.dandiarchive.org/api/assets/{nwb_asset_id}/download/\"\n",
    "print(f\"Loading NWB file from: {nwb_url}\")\n",
    "\n",
    "# Load the NWB file\n",
    "# The following lines are based on the output from `tools_cli.py nwb-file-info`\n",
    "remote_file = remfile.File(nwb_url)\n",
    "h5_file = h5py.File(remote_file, 'r') # Ensure read-only mode\n",
    "io = pynwb.NWBHDF5IO(file=h5_file, mode='r') # Ensure read-only mode\n",
    "nwbfile = io.read()\n",
    "\n",
    "print(\"\\nNWB file loaded successfully.\")\n",
    "print(f\"Identifier: {nwbfile.identifier}\")\n",
    "print(f\"Session description: {nwbfile.session_description}\")\n",
    "print(f\"Session start time: {nwbfile.session_start_time}\")\n",
    "print(f\"Experimenter(s): {nwbfile.experimenter}\")\n",
    "if nwbfile.subject:\n",
    "    print(f\"Subject ID: {nwbfile.subject.subject_id}\")\n",
    "    print(f\"Subject species: {nwbfile.subject.species}\")\n",
    "    print(f\"Subject sex: {nwbfile.subject.sex}\")\n",
    "    print(f\"Subject age: {nwbfile.subject.age}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad193f29",
   "metadata": {},
   "source": [
    "### Neurosift Link for this NWB file\n",
    "\n",
    "You can explore this NWB file interactively on Neurosift using the following link:\n",
    "\n",
    "[https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/a243dde4-c270-42a9-8550-025f5ffcd5a7/download/&dandisetId=001195&dandisetVersion=draft](https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/a243dde4-c270-42a9-8550-025f5ffcd5a7/download/&dandisetId=001195&dandisetVersion=draft)\n",
    "\n",
    "(Note: The `dandisetVersion` in the Neurosift link might sometimes be pinpointing `draft` or a specific published version like `0.250408.1733`. The link provided aims for general accessibility)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc971b3",
   "metadata": {},
   "source": [
    "### Summarizing NWB File Contents\n",
    "\n",
    "Let's look at the structure of this NWB file. NWB files organize data into various groups. Key groups include:\n",
    "- `acquisition`: Raw acquired data, typically time series.\n",
    "- `stimulus`: Stimulus data presented during the experiment.\n",
    "- `processing`: Processed data derived from raw acquisition.\n",
    "- `intervals`: Time intervals of interest, like trials or experimental epochs.\n",
    "- `general`: General metadata about the experiment, subject, etc.\n",
    "\n",
    "We can list the contents of some of these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb1f5b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:58:28.812243Z",
     "iopub.status.busy": "2025-05-09T15:58:28.812151Z",
     "iopub.status.idle": "2025-05-09T15:58:28.823297Z",
     "shell.execute_reply": "2025-05-09T15:58:28.822950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the NWB file:\n",
      "\n",
      "--- Acquisition ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nwbfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContents of the NWB file:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Acquisition ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnwbfile\u001b[49m\u001b[38;5;241m.\u001b[39macquisition:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m acq_name, acq_data \u001b[38;5;129;01min\u001b[39;00m nwbfile\u001b[38;5;241m.\u001b[39macquisition\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macq_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(acq_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nwbfile' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Contents of the NWB file:\")\n",
    "\n",
    "print(\"\\n--- Acquisition ---\")\n",
    "if nwbfile.acquisition:\n",
    "    for acq_name, acq_data in nwbfile.acquisition.items():\n",
    "        print(f\"- {acq_name}: {type(acq_data)}\")\n",
    "        if hasattr(acq_data, 'description'):\n",
    "             print(f\"  Description: {acq_data.description}\")\n",
    "        if hasattr(acq_data, 'data') and hasattr(acq_data.data, 'shape'):\n",
    "             print(f\"  Data shape: {acq_data.data.shape}\")\n",
    "else:\n",
    "    print(\"No data in acquisition group.\")\n",
    "\n",
    "print(\"\\n--- Stimulus ---\")\n",
    "if nwbfile.stimulus:\n",
    "    for stim_name, stim_data in nwbfile.stimulus.items():\n",
    "        print(f\"- {stim_name}: {type(stim_data)}\")\n",
    "        if hasattr(stim_data, 'description'):\n",
    "            print(f\"  Description: {stim_data.description}\")\n",
    "        if hasattr(stim_data, 'data') and hasattr(stim_data.data, 'shape'):\n",
    "            print(f\"  Data shape: {stim_data.data.shape}\")\n",
    "else:\n",
    "    print(\"No data in stimulus group.\")\n",
    "\n",
    "print(\"\\n--- Icephys Electrodes ---\")\n",
    "if nwbfile.icephys_electrodes:\n",
    "    for electrode_name, electrode_data in nwbfile.icephys_electrodes.items():\n",
    "        print(f\"- {electrode_name}: {type(electrode_data)}\")\n",
    "        if hasattr(electrode_data, 'description'):\n",
    "            print(f\"  Description: {electrode_data.description}\")\n",
    "else:\n",
    "    print(\"No icephys electrodes defined.\")\n",
    "\n",
    "print(\"\\n--- Lab Metadata (DandiIcephysMetadata) ---\")\n",
    "if \"DandiIcephysMetadata\" in nwbfile.lab_meta_data:\n",
    "    dandi_meta = nwbfile.lab_meta_data[\"DandiIcephysMetadata\"]\n",
    "    print(f\"- Cell ID: {dandi_meta.cell_id}\")\n",
    "    print(f\"- Slice ID: {dandi_meta.slice_id}\")\n",
    "    print(f\"- Targeted Layer: {dandi_meta.targeted_layer}\")\n",
    "    print(f\"- Inferred Layer: {dandi_meta.inferred_layer}\")\n",
    "else:\n",
    "    print(\"No DandiIcephysMetadata found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7667004d",
   "metadata": {},
   "source": [
    "## 3. Load and Visualize Data from the NWB file\n",
    "\n",
    "This NWB file contains intracellular electrophysiology data, specifically current clamp and voltage clamp series.\n",
    "\n",
    "Let's focus on a `CurrentClampSeries` from the acquisition data. The `tools_cli.py nwb-file-info` output showed many `current_clamp-response-XX-ch-Y` series. We'll pick one, for example, `current_clamp-response-01-ch-0`.\n",
    "\n",
    "The description for these series is: \"Response to: episodic stimulation, 1s steps, 20pA increments, -120pA to 260pA\". This indicates a series of current injection steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b81ec7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:58:28.824625Z",
     "iopub.status.busy": "2025-05-09T15:58:28.824527Z",
     "iopub.status.idle": "2025-05-09T15:58:28.838299Z",
     "shell.execute_reply": "2025-05-09T15:58:28.838049Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nwbfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m series_name_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_clamp-response-01-ch-0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m series_name_stimulus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstimulus-01-ch-0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Corresponding stimulus\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m series_name_response \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnwbfile\u001b[49m\u001b[38;5;241m.\u001b[39macquisition \u001b[38;5;129;01mand\u001b[39;00m series_name_stimulus \u001b[38;5;129;01min\u001b[39;00m nwbfile\u001b[38;5;241m.\u001b[39mstimulus:\n\u001b[1;32m      7\u001b[0m     response_series \u001b[38;5;241m=\u001b[39m nwbfile\u001b[38;5;241m.\u001b[39macquisition[series_name_response]\n\u001b[1;32m      8\u001b[0m     stimulus_series \u001b[38;5;241m=\u001b[39m nwbfile\u001b[38;5;241m.\u001b[39mstimulus[series_name_stimulus]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nwbfile' is not defined"
     ]
    }
   ],
   "source": [
    "# Select a current clamp series to analyze\n",
    "# Based on the nwb-file-info output, these are present.\n",
    "series_name_response = \"current_clamp-response-01-ch-0\"\n",
    "series_name_stimulus = \"stimulus-01-ch-0\" # Corresponding stimulus\n",
    "\n",
    "if series_name_response in nwbfile.acquisition and series_name_stimulus in nwbfile.stimulus:\n",
    "    response_series = nwbfile.acquisition[series_name_response]\n",
    "    stimulus_series = nwbfile.stimulus[series_name_stimulus]\n",
    "\n",
    "    print(f\"Analyzing response: {series_name_response}\")\n",
    "    print(f\"Description: {response_series.description}\")\n",
    "    print(f\"Unit: {response_series.unit}\")\n",
    "    print(f\"Data shape: {response_series.data.shape}\")\n",
    "    print(f\"Sampling rate: {response_series.rate} Hz\")\n",
    "    print(f\"Duration: {response_series.data.shape[0] / response_series.rate} seconds\")\n",
    "\n",
    "    print(f\"\\nAnalyzing stimulus: {series_name_stimulus}\")\n",
    "    print(f\"Description: {stimulus_series.description}\")\n",
    "    print(f\"Unit: {stimulus_series.unit}\")\n",
    "    print(f\"Data shape: {stimulus_series.data.shape}\")\n",
    "\n",
    "    # Load a subset of data to avoid excessive memory usage/download time\n",
    "    num_points_to_load = response_series.data.shape[0] # Load all points for this short series\n",
    "    \n",
    "    # Data is stored as raw values and needs conversion\n",
    "    # data = (raw_data * conversion) + offset\n",
    "    response_data_raw = response_series.data[:num_points_to_load]\n",
    "    response_data_converted = (response_data_raw * response_series.conversion) + response_series.offset\n",
    "\n",
    "    stimulus_data_raw = stimulus_series.data[:num_points_to_load]\n",
    "    stimulus_data_converted = (stimulus_data_raw * stimulus_series.conversion) + stimulus_series.offset\n",
    "    \n",
    "    # Create a time vector\n",
    "    time_vector = np.arange(num_points_to_load) / response_series.rate\n",
    "\n",
    "    # Plot the data\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "    # Plot response\n",
    "    axs[0].plot(time_vector, response_data_converted)\n",
    "    axs[0].set_title(f\"Response: {series_name_response}\")\n",
    "    axs[0].set_ylabel(f\"Voltage ({response_series.unit})\")\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Plot stimulus\n",
    "    axs[1].plot(time_vector, stimulus_data_converted)\n",
    "    axs[1].set_title(f\"Stimulus: {series_name_stimulus}\")\n",
    "    axs[1].set_ylabel(f\"Current ({stimulus_series.unit})\")\n",
    "    axs[1].set_xlabel(\"Time (s)\")\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"Could not find {series_name_response} in acquisition or {series_name_stimulus} in stimulus.\")\n",
    "    print(\"Available acquisition series:\", list(nwbfile.acquisition.keys()))\n",
    "    print(\"Available stimulus series:\", list(nwbfile.stimulus.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38643b5b",
   "metadata": {},
   "source": [
    "The plot above shows the recorded membrane potential (top panel) in response to a current injection (bottom panel) for the first segment of an episodic stimulation protocol. The description indicates that this protocol involves 1-second steps with 20pA increments. This specific trace likely corresponds to one of these steps. The data shape (3000 points) and sampling rate (10000 Hz) suggest a duration of 0.3 seconds for this particular segment, not 1s as the overall protocol step. It's possible `current_clamp-response-01-ch-0` is one part of a longer sequence making up a full 1s step, or the description refers to the overall design rather than each individual data snippet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d7898",
   "metadata": {},
   "source": [
    "### Visualizing Multiple Sweeps\n",
    "\n",
    "The NWB file contains many current clamp series, likely corresponding to different current injection levels from the episodic stimulation protocol. Let's try to plot a few of these sweeps together to see how the cell responds to varying stimuli. We'll select a few consecutive response series (e.g., `current_clamp-response-01-ch-0` through `current_clamp-response-05-ch-0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519c64e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:58:28.840000Z",
     "iopub.status.busy": "2025-05-09T15:58:28.839842Z",
     "iopub.status.idle": "2025-05-09T15:58:28.851988Z",
     "shell.execute_reply": "2025-05-09T15:58:28.851659Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m response_series_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_clamp-response-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-ch-0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_sweeps_to_plot \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m      4\u001b[0m stimulus_series_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstimulus-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-ch-0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_sweeps_to_plot \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m----> 6\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Plot responses\u001b[39;00m\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Select a few response series to plot together\n",
    "num_sweeps_to_plot = 5 # For example, plot 5 sweeps\n",
    "response_series_names = [f\"current_clamp-response-{i:02d}-ch-0\" for i in range(1, num_sweeps_to_plot + 1)]\n",
    "stimulus_series_names = [f\"stimulus-{i:02d}-ch-0\" for i in range(1, num_sweeps_to_plot + 1)]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot responses\n",
    "plt.subplot(2, 1, 1)\n",
    "all_responses_valid = True\n",
    "for i, series_name in enumerate(response_series_names):\n",
    "    if series_name in nwbfile.acquisition:\n",
    "        series = nwbfile.acquisition[series_name]\n",
    "        data_raw = series.data[:] # Load all data for these relatively short series\n",
    "        data_converted = (data_raw * series.conversion) + series.offset\n",
    "        time_vector = (np.arange(len(data_converted)) / series.rate) + series.starting_time\n",
    "        plt.plot(time_vector, data_converted, label=f\"{series_name} (Start: {series.starting_time:.2f}s)\")\n",
    "    else:\n",
    "        print(f\"Warning: Response series {series_name} not found.\")\n",
    "        all_responses_valid = False\n",
    "if all_responses_valid:\n",
    "    plt.title(f\"Overlay of First {num_sweeps_to_plot} Current Clamp Responses (Channel 0)\")\n",
    "    plt.ylabel(f\"Voltage ({nwbfile.acquisition[response_series_names[0]].unit if response_series_names[0] in nwbfile.acquisition else 'V'})\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.legend(loc='upper right', fontsize='small')\n",
    "    plt.grid(True)\n",
    "else:\n",
    "    plt.title(f\"Could not plot all requested response sweeps.\")\n",
    "\n",
    "\n",
    "# Plot stimuli\n",
    "plt.subplot(2, 1, 2)\n",
    "all_stimuli_valid = True\n",
    "for i, series_name in enumerate(stimulus_series_names):\n",
    "    if series_name in nwbfile.stimulus:\n",
    "        series = nwbfile.stimulus[series_name]\n",
    "        data_raw = series.data[:]\n",
    "        data_converted = (data_raw * series.conversion) + series.offset\n",
    "        time_vector = (np.arange(len(data_converted)) / series.rate) + series.starting_time\n",
    "        plt.plot(time_vector, data_converted, label=f\"{series_name} (Start: {series.starting_time:.2f}s)\")\n",
    "    else:\n",
    "        print(f\"Warning: Stimulus series {series_name} not found.\")\n",
    "        all_stimuli_valid = False\n",
    "\n",
    "if all_stimuli_valid:\n",
    "    plt.title(f\"Overlay of First {num_sweeps_to_plot} Current Clamp Stimuli (Channel 0)\")\n",
    "    plt.ylabel(f\"Current ({nwbfile.stimulus[stimulus_series_names[0]].unit if stimulus_series_names[0] in nwbfile.stimulus else 'A'})\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.legend(loc='upper right', fontsize='small')\n",
    "    plt.grid(True)\n",
    "else:\n",
    "    plt.title(f\"Could not plot all requested stimulus sweeps.\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189239f7",
   "metadata": {},
   "source": [
    "The plots display the first few electrophysiological sweeps from the experiment. The top panel shows the voltage responses, and the bottom panel shows the corresponding current stimuli. Each sweep starts at a different time, as indicated by their `starting_time` attribute, suggesting they are sequential segments of the stimulation protocol. The current steps seem to increase with each sweep, which is consistent with the protocol description (\"20pA increments\"). The neuron's response to these current injections can be observed in the voltage traces. For instance, larger depolarizing current steps might elicit action potentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0450ad0",
   "metadata": {},
   "source": [
    "### Exploring `icephys_sequential_recordings` Table\n",
    "\n",
    "The NWB file also contains tables that organize these recordings. The `icephys_sequential_recordings` table groups sweeps that belong to the same experimental protocol. Let's inspect this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8efbdb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:58:28.853007Z",
     "iopub.status.busy": "2025-05-09T15:58:28.852905Z",
     "iopub.status.idle": "2025-05-09T15:58:28.861377Z",
     "shell.execute_reply": "2025-05-09T15:58:28.861004Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nwbfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnwbfile\u001b[49m\u001b[38;5;241m.\u001b[39micephys_sequential_recordings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIcephys Sequential Recordings Table:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Convert to pandas DataFrame for easier viewing if desired and if pandas is available\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nwbfile' is not defined"
     ]
    }
   ],
   "source": [
    "if nwbfile.icephys_sequential_recordings is not None:\n",
    "    print(\"Icephys Sequential Recordings Table:\")\n",
    "    # Convert to pandas DataFrame for easier viewing if desired and if pandas is available\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        sequential_df = nwbfile.icephys_sequential_recordings.to_dataframe()\n",
    "        print(sequential_df.head())\n",
    "\n",
    "        # This table groups 'simultaneous_recordings'. Each row here represents an experimental paradigm\n",
    "        # (e.g., a series of current steps).\n",
    "        # 'simultaneous_recordings' column itself is a VectorIndex, pointing to rows in\n",
    "        # the 'icephys_simultaneous_recordings' table.\n",
    "\n",
    "        print(\"\\nExample: First sequential recording details\")\n",
    "        first_seq_rec = sequential_df.iloc[0]\n",
    "        print(f\"Stimulus Type: {first_seq_rec['stimulus_type']}\")\n",
    "\n",
    "        # Get the set of simultaneous recordings associated with this sequential recording\n",
    "        # The 'simultaneous_recordings' column in sequential_df contains DynamicTableRegion objects.\n",
    "        # These are references to rows in the nwbfile.icephys_simultaneous_recordings table.\n",
    "        # sim_rec_indices = first_seq_rec['simultaneous_recordings'] # This is a DynamicTableRegion\n",
    "        # print(f\"Number of simultaneous recordings in this sequence: {len(sim_rec_indices)}\")\n",
    "        \n",
    "        # For more detailed introspection:\n",
    "        # sim_recordings_df = nwbfile.icephys_simultaneous_recordings.to_dataframe()\n",
    "        # referenced_sim_recs = sim_recordings_df.iloc[sim_rec_indices.data[:]]\n",
    "        # print(referenced_sim_recs.head())\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"Pandas not installed. Cannot display table as DataFrame.\")\n",
    "        print(\"Columns:\", nwbfile.icephys_sequential_recordings.colnames)\n",
    "        # You could iterate through rows manually if pandas isn't available, but it's more verbose.\n",
    "    except Exception as e:\n",
    "        print(f\"Error displaying icephys_sequential_recordings table: {e}\")\n",
    "else:\n",
    "    print(\"No icephys_sequential_recordings table found in this NWB file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d1636",
   "metadata": {},
   "source": [
    "The `icephys_sequential_recordings` table provides a high-level organization of the experimental protocol. Each row typically corresponds to a particular type of stimulus applied (e.g., \"episodic stimulation\"). Understanding this table can help in programmatically accessing all sweeps related to a specific experimental condition. The `tools_cli.py` output for `nwb-file-info` indicates that the `icephys_sequential_recordings` table in this file has 5 rows, and its columns are `simultaneous_recordings` and `stimulus_type`. This suggests 5 distinct \"sequences\" or experimental blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f015665",
   "metadata": {},
   "source": [
    "## 4. Summary and Future Directions\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "1.  Connect to the DANDI Archive and retrieve metadata for Dandiset 001195.\n",
    "2.  List assets within the Dandiset.\n",
    "3.  Load a specific NWB file (`sub-23/sub-23_ses-20150324T134114_slice-slice-1_cell-C1_icephys.nwb`) using its DANDI asset URL.\n",
    "4.  Inspect basic metadata and structure of the NWB file.\n",
    "5.  Access and visualize intracellular electrophysiology data (current clamp series and their corresponding stimuli).\n",
    "6.  Briefly look at how recordings are organized in `icephys_sequential_recordings` table.\n",
    "\n",
    "### Possible Future Directions:\n",
    "\n",
    "*   **Further Ephys Analysis:**\n",
    "    *   Analyze other sweeps and channels (e.g., `ch-1` which is also present).\n",
    "    *   Extract features from the responses, such as action potential threshold, firing frequency, input resistance, sag potential, etc., for different current injection levels.\n",
    "    *   Compare responses across different cells or experimental conditions if other NWB files from this Dandiset are analyzed.\n",
    "    *   Investigate data from `voltage_clamp-response-XX` series, which are also present in this file.\n",
    "*   **Exploring Other Data Types:** This Dandiset also mentions calcium imaging data and behavioral videos in its overall description. Other NWB files within this Dandiset might contain these data types, which could be explored similarly.\n",
    "*   **Relating to Experimental Context:** Connect the observed electrophysiological properties to the broader research questions of the Dandiset concerning dorsal raphe dopamine projections and loneliness-like states, if applicable to the ex vivo data. This often requires more detailed knowledge of the experimental design for each specific file.\n",
    "\n",
    "This notebook provides a starting point for exploring the rich data available in Dandiset 001195. Remember to consult the original publication and DANDI metadata for a complete understanding of the experimental design and context.\n",
    "\n",
    "---\n",
    "*End of AI-generated notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61ccedb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:58:28.862473Z",
     "iopub.status.busy": "2025-05-09T15:58:28.862387Z",
     "iopub.status.idle": "2025-05-09T15:58:28.865356Z",
     "shell.execute_reply": "2025-05-09T15:58:28.864768Z"
    }
   },
   "outputs": [],
   "source": [
    "# Final check to close NWB I/O object if it was opened\n",
    "# This helps release the file handle, especially for remote files.\n",
    "if 'io' in locals() and io is not None:\n",
    "    try:\n",
    "        io.close()\n",
    "        print(\"\\nNWBHDF5IO closed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error closing NWBHDF5IO: {e}\")\n",
    "\n",
    "if 'h5_file' in locals() and h5_file is not None:\n",
    "    try:\n",
    "        h5_file.close()\n",
    "        print(\"HDF5 file (from remfile) closed.\")\n",
    "    except Exception as e:\n",
    "        # h5py file might be already closed if io.close() cascades, or if it was never opened properly.\n",
    "        # print(f\"Error closing HDF5 file: {e}\")\n",
    "        pass # Often this is fine, especially if io.close() handled it.\n",
    "\n",
    "if 'remote_file' in locals() and remote_file is not None:\n",
    "    try:\n",
    "        remote_file.close() # remfile.File also has a close method.\n",
    "        print(\"remfile.File closed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error closing remfile: {e}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
